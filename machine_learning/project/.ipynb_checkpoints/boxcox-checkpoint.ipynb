{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = df.iloc[:, 0:len(df.columns)-1]\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "Y = df.loc[:, 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox transform the Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_boxcox, lmda = boxcox(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use inv_boxcox to transform predicitions back into the native scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.639999, 19.919998, 21.150001, ..., 23.36    , 20.1407  ,\n",
       "       21.3     ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox(Y_boxcox, lmda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n",
    "train_X_bc, val_X_bc, train_Y_bc, val_Y_bc = train_test_split(X, Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline predictions for each transformation of Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, guess the average of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline MAE:  0.93\n",
      "BoxCox Average baseline MAE:  0.93\n"
     ]
    }
   ],
   "source": [
    "baseline_preds = val_Y.mean()\n",
    "baseline_errors = abs(val_Y - baseline_preds)\n",
    "print('Average baseline MAE: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "baseline_preds_bc = val_Y_bc.mean()\n",
    "baseline_errors_bc = abs(val_Y_bc - baseline_preds_bc)\n",
    "print('BoxCox Average baseline MAE: ', round(np.mean(baseline_errors_bc), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'alpha': [0.4, 0.5, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.7, 0.8, 0.9, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best gamma for both normal and boxcox transformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.62}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring='neg_mean_absolute_error')\n",
    "clf.fit(train_X, train_Y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.62}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bc =  GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring='neg_mean_absolute_error')\n",
    "clf.fit(train_X_bc, train_Y_bc)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.93\n"
     ]
    }
   ],
   "source": [
    "lasso_fit = Lasso(0.62, random_state=450, tol=0.0000000001)\n",
    "lasso_fit = lasso_fit.fit(train_X, train_Y)\n",
    "\n",
    "predictions = lasso_fit.predict(val_X)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y - predictions)\n",
    "\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "coef = lasso_fit.coef_\n",
    "\n",
    "lasso_features = train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num1', 'num30', 'num37', 'num59'], dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE BoxCox: 0.93\n",
      "MAE BoxCox, Transformed: 11.78\n"
     ]
    }
   ],
   "source": [
    "lasso_fit_bc = lasso_fit.fit(train_X_bc, train_Y_bc)\n",
    "\n",
    "predictions = lasso_fit_bc.predict(val_X_bc)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y_bc - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "\n",
    "print('MAE BoxCox:', round(np.mean(errors), 2))\n",
    "print('MAE BoxCox, Transformed:', round(np.mean(errors_trans), 2))\n",
    "\n",
    "\n",
    "# Check out non-zero coefficients \n",
    "coef = lasso_fit_bc.coef_\n",
    "\n",
    "#train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a hyperparameter grid search: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 2, 4],\n",
    "        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1],\n",
    "        'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "        'max_depth': [3, 5, 6, 8]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.2, n_estimators=600, objective='reg:linear', eval_metric='mae',\n",
    "                    silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 31.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000000957E6AB570>,\n",
       "          error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eval_metric='mae', gamma=0, learning_rate=0.2,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=600, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=4,\n",
       "          param_distributions={'min_child_weight': [1, 2, 4], 'gamma': [0, 0.5, 1, 1.5, 2, 5], 'subsample': [0.6, 0.8, 1], 'colsample_bytree': [0.5, 0.7, 0.9], 'max_depth': [3, 5, 6, 8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_absolute_error',\n",
       "          verbose=3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 50\n",
    "\n",
    "kf = KFold(n_splits=folds,shuffle=True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb,\n",
    "                                   scoring='neg_mean_absolute_error', n_jobs=4,\n",
    "                                   cv=kf.split(train_X,train_Y), verbose=3, random_state=1001 )\n",
    "\n",
    "random_search.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'gamma': 5,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 2,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE BoxCox: 0.98\n",
      "MAE BoxCox, Transformed: 11.78\n"
     ]
    }
   ],
   "source": [
    "predictions = random_search.predict(val_X)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "\n",
    "print('MAE BoxCox:', round(np.mean(errors), 2))\n",
    "print('MAE BoxCox, Transformed:', round(np.mean(errors_trans), 2))\n",
    "\n",
    "\n",
    "# Check out non-zero coefficients \n",
    "#coef = lasso_fit_bc.coef_\n",
    "\n",
    "#train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best params to fit some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.1, n_estimators=1000, objective='reg:linear', eval_metric='mae',\n",
    "                    silent=True, **random_search.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.97\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X, train_Y)\n",
    "predictions = xgb.predict(val_X)\n",
    "errors = abs(val_Y - predictions)\n",
    "print(\"MAE: \", round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Boxcox:  0.97\n",
      "MAE un-Boxcox:  11.78\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X_bc, train_Y_bc)\n",
    "predictions = xgb.predict(val_X_bc)\n",
    "errors = abs(val_Y_bc - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "print(\"MAE Boxcox: \", round(np.mean(errors), 2))\n",
    "print(\"MAE un-Boxcox: \", round(np.mean(errors_trans), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, We must standardize the input to be between 1 and 0\n",
    "\n",
    "Also, let's start off with only the features identified to be useful to lasso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_std(column):\n",
    "    # Helper function, range standardizes a list of values\n",
    "    return (column - column.min())/(column.max() - column.min())\n",
    "\n",
    "def range_std_reversible(column):\n",
    "    # Helper function, range standardizes a list of values\n",
    "    # Returns min and max for later reversal\n",
    "    return (column - column.min())/(column.max() - column.min()), column.min(), column.max()\n",
    "\n",
    "def range_std_reverse(column, min_val, max_value):\n",
    "    return (column*(max_value - min_val) + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_standardize = [*lasso_features, 'target']\n",
    "df_thin = df.loc[:, features_to_standardize]\n",
    "for column_name in features_to_standardize:\n",
    "    df_thin[column_name] = range_std(df_thin[column_name])\n",
    "    \n",
    "df_thin.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these as our training set\n",
    "trainY_std = df_thin.loc[:, 'target']\n",
    "trainX_std = df_thin.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxcox transform\n",
    "trainY_std_bc, min_value, max_value = range_std_reversible(Y_boxcox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_std, val_X_std, train_Y_std, val_Y_std = train_test_split(trainX_std, trainY_std, test_size = 0.20, random_state = 42)\n",
    "train_X_std_bc, val_X_std_bc, train_Y_std_bc, val_Y_std_bc = train_test_split(trainX_std, trainY_std_bc, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.639999, 19.919998, 21.150001, ..., 23.36    , 20.1407  ,\n",
       "       21.3     ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we will return the range standardized, boxcox transformed values to their original scale\n",
    "inv_boxcox(range_std_reverse(trainY_std_bc, min_value, max_value), lmda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Nueral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplemodel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_shape= (4,), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    sgd = SGD(lr=0.09, momentum=0.8, decay=0.00)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.2313\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0628\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0583\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0557\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0534\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0527\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0488\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0465\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0445\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0437\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0420\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0412\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0406\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0404\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0400\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0396\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0396\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0394\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0393\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0393\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0393\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0393\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 40us/step - loss: 0.0393\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0392\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 40us/step - loss: 0.0392\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0393\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0393\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0393\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0393\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0392\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0393\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0392\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0391\n",
      "1270/1270 [==============================] - 0s 50us/step\n",
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 0s 79us/step - loss: 0.2415\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0682\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0620\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0582\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0557\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0515\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0496\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0464\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0449\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0430\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0416\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0407\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0401\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0397\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0394\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0393\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0393\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0394\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0393\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0393\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0392\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0393\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0393\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0392\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0392\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0393\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 96/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0392\n",
      "1270/1270 [==============================] - 0s 49us/step\n",
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 0s 83us/step - loss: 0.2648\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0673\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0606\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0593\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0556\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0523\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0495\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0471\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0448\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0437\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0420\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0412\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0404\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0401\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0397\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0397\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0396\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0396\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0394\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0394\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0396\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0395\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0395\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0395\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0395\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0395\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 96/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0394\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0396\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0395\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0394\n",
      "1270/1270 [==============================] - 0s 58us/step\n",
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 0s 84us/step - loss: 0.2931\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0689\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0601\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0577\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0553\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0521\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0494\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0469\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0448\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0431\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0416\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0409\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0401\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0397\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0396\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0393\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0393\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0391\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0391\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0391\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0391\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0391\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0391\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0391\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0391\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0391\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0391\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0391\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 96/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0391\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 44us/step - loss: 0.0391\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0391\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "1270/1270 [==============================] - 0s 64us/step\n",
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 0s 93us/step - loss: 0.2604\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0696\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0626\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0587\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0550\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0522\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0491\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0469\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0449\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0431\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0414\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0406\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0402\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0397\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0394\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0394\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0394\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0393\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0393\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0393\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0393\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0393\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0393\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0392\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0393\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0392\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0391\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 29us/step - loss: 0.0392\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0392\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0392\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0391\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 28us/step - loss: 0.0391\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0392\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 96/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0391\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0392\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 31us/step - loss: 0.0392\n",
      "1270/1270 [==============================] - 0s 72us/step\n",
      "Standardized: -0.04 (0.00) MAE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "results = cross_val_score(pipeline, np.array(trainX_std), np.array(trainY_std), cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MAE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 1s 119us/step - loss: 0.2027\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0593\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0568\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0540\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0528\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0502\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0478\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0471\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0456\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0443\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 46us/step - loss: 0.0431\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0424\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 50us/step - loss: 0.0416\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0410\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0404\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0403\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0399\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0399\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0398\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0396\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0396\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 48us/step - loss: 0.0395\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0396\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 42us/step - loss: 0.0395\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 51us/step - loss: 0.0395\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 50us/step - loss: 0.0395\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 46us/step - loss: 0.0395\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 47us/step - loss: 0.0395\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 46us/step - loss: 0.0395\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0394\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 46us/step - loss: 0.0395\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 47us/step - loss: 0.0395\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 43us/step - loss: 0.0395\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0395\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0395\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0394\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0395\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0395\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 51us/step - loss: 0.0394\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0395\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0394\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 49us/step - loss: 0.0396\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0394\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 40us/step - loss: 0.0394\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 43us/step - loss: 0.0395\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0394\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0394\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0394\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0394\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 44us/step - loss: 0.0395\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0395\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0394\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0394\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0395\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0395\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x950aab0d68>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn = KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)\n",
    "snn.fit(train_X_std, train_Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 0s 19us/step\n",
      "MAE:  0.94\n"
     ]
    }
   ],
   "source": [
    "preds = snn.predict(val_X_std)\n",
    "preds = range_std_reverse(preds, df.target.min(), df.target.max())\n",
    "actual = range_std_reverse(val_Y_std, df.target.min(), df.target.max())\n",
    "\n",
    "errors = abs(actual - preds)\n",
    "\n",
    "print(\"MAE: \", round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 1s 109us/step - loss: 0.2547\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0641\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0599\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0579\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0544\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0529\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 32us/step - loss: 0.0491\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0469\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0455\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0441\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0424\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0412\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0408\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0405\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0400\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0399\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 41us/step - loss: 0.0398\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0397\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0396\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 30us/step - loss: 0.0396\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0396\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0396\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 33us/step - loss: 0.0395\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 47us/step - loss: 0.0396\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 40us/step - loss: 0.0395\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0396\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 47us/step - loss: 0.0395\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0396\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 38us/step - loss: 0.0395\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 34us/step - loss: 0.0395\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 35us/step - loss: 0.0395\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 43us/step - loss: 0.0395\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 43us/step - loss: 0.0395\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 40us/step - loss: 0.0395\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 36us/step - loss: 0.0395\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 40us/step - loss: 0.0395\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 39us/step - loss: 0.0395\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 37us/step - loss: 0.0395\n",
      "Epoch 83/100\n",
      "  32/5080 [..............................] - ETA: 0s - loss: 0.0384"
     ]
    }
   ],
   "source": [
    "snn_std = KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)\n",
    "snn.fit(train_X_std, train_Y_std_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 0s 100us/step\n",
      "MAE :  0.11\n",
      "MAE Untransformed:  0.64\n"
     ]
    }
   ],
   "source": [
    "preds_raw = snn.predict(val_X_std)\n",
    "preds = range_std_reverse(preds_raw, df.target.min(), df.target.max()), lmda)\n",
    "actual = inv_boxcox(range_std_reverse(val_Y_std_bc, df.target.min(), df.target.max()), lmda)\n",
    "\n",
    "errors = abs(actual - preds)\n",
    "\n",
    "print(\"MAE : \", round(np.mean(abs(val_Y_std_bc - preds_raw)), 2))\n",
    "print(\"MAE Untransformed: \", round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730     20.220002\n",
       "2131    17.699997\n",
       "3070    19.968800\n",
       "4283    20.410000\n",
       "217     19.639999\n",
       "3545    19.780000\n",
       "4080    21.420000\n",
       "3674    20.640000\n",
       "6176    23.812500\n",
       "4615    19.062500\n",
       "3459    22.750000\n",
       "4373    19.370000\n",
       "465     18.869995\n",
       "5703    19.570010\n",
       "2981    19.889999\n",
       "1183    21.809998\n",
       "4040    19.790010\n",
       "3680    20.420000\n",
       "1263    19.900009\n",
       "3622    19.812500\n",
       "3214    20.406200\n",
       "746     18.269997\n",
       "1611    20.019989\n",
       "4684    20.390000\n",
       "80      20.649994\n",
       "3784    17.590000\n",
       "2882    21.125000\n",
       "1616    19.330001\n",
       "6296    21.670000\n",
       "3612    22.240000\n",
       "          ...    \n",
       "509     20.290001\n",
       "5772    18.120000\n",
       "2153    19.859401\n",
       "4851    19.593700\n",
       "748     19.800003\n",
       "1617    19.889999\n",
       "5271    20.812500\n",
       "2404    20.718697\n",
       "5986    17.370000\n",
       "3313    20.750000\n",
       "2024    20.000000\n",
       "4546    20.921900\n",
       "5556    24.990010\n",
       "2181    18.500000\n",
       "471     20.589997\n",
       "5139    20.920000\n",
       "3961    18.630000\n",
       "2619    20.390594\n",
       "5462    19.890000\n",
       "5996    17.375000\n",
       "3096    20.015700\n",
       "896     22.370010\n",
       "4796    19.765600\n",
       "251     24.437500\n",
       "1209    20.020005\n",
       "3525    20.430010\n",
       "3942    21.406200\n",
       "2895    20.250000\n",
       "1128    22.640000\n",
       "4724    20.656300\n",
       "Name: target, Length: 1270, dtype: float64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_std_reverse(val_Y_std, df.target.min(), df.target.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.66631891, 7.04946254, 7.60392998, ..., 7.67378152, 8.27610485,\n",
       "       7.77510922])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
