{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = df.iloc[:, 0:len(df.columns)-1]\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "Y = df.loc[:, 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox transform the Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_boxcox, lmda = boxcox(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use inv_boxcox to transform predicitions back into the native scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.639999, 19.919998, 21.150001, ..., 23.36    , 20.1407  ,\n",
       "       21.3     ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox(Y_boxcox, lmda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n",
    "train_X_bc, val_X_bc, train_Y_bc, val_Y_bc = train_test_split(X, Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline predictions for each transformation of Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, guess the average of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline MAE:  0.93\n",
      "BoxCox Average baseline MAE:  0.93\n"
     ]
    }
   ],
   "source": [
    "baseline_preds = val_Y.mean()\n",
    "baseline_errors = abs(val_Y - baseline_preds)\n",
    "print('Average baseline MAE: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "baseline_preds_bc = val_Y_bc.mean()\n",
    "baseline_errors_bc = abs(val_Y_bc - baseline_preds_bc)\n",
    "print('BoxCox Average baseline MAE: ', round(np.mean(baseline_errors_bc), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'alpha': [0.4, 0.5, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.7, 0.8, 0.9, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best gamma for both normal and boxcox transformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.62}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring='neg_mean_absolute_error')\n",
    "clf.fit(train_X, train_Y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.62}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bc =  GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring='neg_mean_absolute_error')\n",
    "clf.fit(train_X_bc, train_Y_bc)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.93\n"
     ]
    }
   ],
   "source": [
    "lasso_fit = Lasso(0.62, random_state=450, tol=0.0000000001)\n",
    "lasso_fit = lasso_fit.fit(train_X, train_Y)\n",
    "\n",
    "predictions = lasso_fit.predict(val_X)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y - predictions)\n",
    "\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "coef = lasso_fit.coef_\n",
    "\n",
    "lasso_features = train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num1', 'num30', 'num37', 'num59'], dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE BoxCox: 0.93\n",
      "MAE BoxCox, Transformed: 11.78\n"
     ]
    }
   ],
   "source": [
    "lasso_fit_bc = lasso_fit.fit(train_X_bc, train_Y_bc)\n",
    "\n",
    "predictions = lasso_fit_bc.predict(val_X_bc)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y_bc - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "\n",
    "print('MAE BoxCox:', round(np.mean(errors), 2))\n",
    "print('MAE BoxCox, Transformed:', round(np.mean(errors_trans), 2))\n",
    "\n",
    "\n",
    "# Check out non-zero coefficients \n",
    "coef = lasso_fit_bc.coef_\n",
    "\n",
    "#train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a hyperparameter grid search: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 2, 4],\n",
    "        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1],\n",
    "        'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "        'max_depth': [3, 5, 6, 8]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.2, n_estimators=600, objective='reg:linear', eval_metric='mae',\n",
    "                    silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 31.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000000957E6AB570>,\n",
       "          error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eval_metric='mae', gamma=0, learning_rate=0.2,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=600, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=4,\n",
       "          param_distributions={'min_child_weight': [1, 2, 4], 'gamma': [0, 0.5, 1, 1.5, 2, 5], 'subsample': [0.6, 0.8, 1], 'colsample_bytree': [0.5, 0.7, 0.9], 'max_depth': [3, 5, 6, 8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_absolute_error',\n",
       "          verbose=3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 50\n",
    "\n",
    "kf = KFold(n_splits=folds,shuffle=True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb,\n",
    "                                   scoring='neg_mean_absolute_error', n_jobs=4,\n",
    "                                   cv=kf.split(train_X,train_Y), verbose=3, random_state=1001 )\n",
    "\n",
    "random_search.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'gamma': 5,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 2,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE BoxCox: 0.98\n",
      "MAE BoxCox, Transformed: 11.78\n"
     ]
    }
   ],
   "source": [
    "predictions = random_search.predict(val_X)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "\n",
    "print('MAE BoxCox:', round(np.mean(errors), 2))\n",
    "print('MAE BoxCox, Transformed:', round(np.mean(errors_trans), 2))\n",
    "\n",
    "\n",
    "# Check out non-zero coefficients \n",
    "#coef = lasso_fit_bc.coef_\n",
    "\n",
    "#train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best params to fit some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.1, n_estimators=1000, objective='reg:linear', eval_metric='mae',\n",
    "                    silent=True, **random_search.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.97\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X, train_Y)\n",
    "predictions = xgb.predict(val_X)\n",
    "errors = abs(val_Y - predictions)\n",
    "print(\"MAE: \", round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Boxcox:  0.97\n",
      "MAE un-Boxcox:  11.78\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X_bc, train_Y_bc)\n",
    "predictions = xgb.predict(val_X_bc)\n",
    "errors = abs(val_Y_bc - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "print(\"MAE Boxcox: \", round(np.mean(errors), 2))\n",
    "print(\"MAE un-Boxcox: \", round(np.mean(errors_trans), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, We must standardize the input to be between 1 and 0\n",
    "\n",
    "Also, let's start off with only the features identified to be useful to lasso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_std(column):\n",
    "    # Helper function, range standardizes a list of values\n",
    "    return (column - column.min())/(column.max() - column.min())\n",
    "\n",
    "def range_std_reversible(column):\n",
    "    # Helper function, range standardizes a list of values\n",
    "    # Returns min and max for later reversal\n",
    "    return (column - column.min())/(column.max() - column.min()), column.min(), column.max()\n",
    "\n",
    "def range_std_reverse(column, min_val, max_value):\n",
    "    return (column*(max_value - min_val) + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_standardize = [*lasso_features, 'target']\n",
    "df_thin = df.loc[:, features_to_standardize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in features_to_standardize:\n",
    "    df_thin[column_name] = range_std(df_thin[column_name])\n",
    "    \n",
    "df_thin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these as our training set\n",
    "trainY_std = df_thin.loc[:, 'target']\n",
    "trainX_std = df_thin.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxcox transform\n",
    "trainY_std_bc, min_value, max_value = range_std_reversible(trainY_boxcox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.639999, 19.919998, 21.150001, ..., 23.36    , 20.1407  ,\n",
       "       21.3     ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we will return the range standardized, boxcox transformed values to their original scale\n",
    "inv_boxcox(range_std_reverse(trainY_std_bc, min_value, max_value), lmda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Nueral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num1', 'num30', 'num37', 'num59'], dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplemodel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_shape= (4,), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    sgd = SGD(lr=0.09, momentum=0.8, decay=0.00)\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-841b4755b870>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mlp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msimplemodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "results = cross_val_score(pipeline, np.array(trainX_std), np.array(trainY_std), cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MAE\" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
