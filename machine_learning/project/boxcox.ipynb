{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = df.iloc[:, 0:len(df.columns)-1]\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "Y = df.loc[:, 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox transform the Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_boxcox, lmda = boxcox(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use inv_boxcox to transform predicitions back into the native scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.639999, 19.919998, 21.150001, ..., 23.36    , 20.1407  ,\n",
       "       21.3     ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_boxcox(Y_boxcox, lmda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size = 0.20, random_state = 42)\n",
    "train_X_bc, val_X_bc, train_Y_bc, val_Y_bc = train_test_split(X, Y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline predictions for each transformation of Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, guess the average of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline MAE:  0.93\n",
      "BoxCox Average baseline MAE:  0.93\n"
     ]
    }
   ],
   "source": [
    "baseline_preds = val_Y.mean()\n",
    "baseline_errors = abs(val_Y - baseline_preds)\n",
    "print('Average baseline MAE: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "baseline_preds_bc = val_Y_bc.mean()\n",
    "baseline_errors_bc = abs(val_Y_bc - baseline_preds_bc)\n",
    "print('BoxCox Average baseline MAE: ', round(np.mean(baseline_errors_bc), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'alpha': [0.4, 0.5, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.7, 0.8, 0.9, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best gamma for both normal and boxcox transformed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.62}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring='neg_mean_absolute_error')\n",
    "clf.fit(train_X, train_Y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.62}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_bc =  GridSearchCV(Lasso(), tuned_parameters, cv=5,\n",
    "                       scoring='neg_mean_absolute_error')\n",
    "clf.fit(train_X_bc, train_Y_bc)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.93\n"
     ]
    }
   ],
   "source": [
    "lasso_fit = Lasso(0.62, random_state=450, tol=0.0000000001)\n",
    "lasso_fit = lasso_fit.fit(train_X, train_Y)\n",
    "\n",
    "predictions = lasso_fit.predict(val_X)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y - predictions)\n",
    "\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))\n",
    "\n",
    "coef = lasso_fit.coef_\n",
    "\n",
    "lasso_features = train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num1', 'num30', 'num37', 'num59'], dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE BoxCox: 0.93\n",
      "MAE BoxCox, Transformed: 11.78\n"
     ]
    }
   ],
   "source": [
    "lasso_fit_bc = lasso_fit.fit(train_X_bc, train_Y_bc)\n",
    "\n",
    "predictions = lasso_fit_bc.predict(val_X_bc)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y_bc - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "\n",
    "print('MAE BoxCox:', round(np.mean(errors), 2))\n",
    "print('MAE BoxCox, Transformed:', round(np.mean(errors_trans), 2))\n",
    "\n",
    "\n",
    "# Check out non-zero coefficients \n",
    "coef = lasso_fit_bc.coef_\n",
    "\n",
    "#train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a hyperparameter grid search: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 2, 4],\n",
    "        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1],\n",
    "        'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "        'max_depth': [3, 5, 6, 8]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.2, n_estimators=600, objective='reg:linear', eval_metric='mae',\n",
    "                    silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 31.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x000000957E6AB570>,\n",
       "          error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eval_metric='mae', gamma=0, learning_rate=0.2,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=600, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=4,\n",
       "          param_distributions={'min_child_weight': [1, 2, 4], 'gamma': [0, 0.5, 1, 1.5, 2, 5], 'subsample': [0.6, 0.8, 1], 'colsample_bytree': [0.5, 0.7, 0.9], 'max_depth': [3, 5, 6, 8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_absolute_error',\n",
       "          verbose=3)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 50\n",
    "\n",
    "kf = KFold(n_splits=folds,shuffle=True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb,\n",
    "                                   scoring='neg_mean_absolute_error', n_jobs=4,\n",
    "                                   cv=kf.split(train_X,train_Y), verbose=3, random_state=1001 )\n",
    "\n",
    "random_search.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'gamma': 5,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 2,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE BoxCox: 0.98\n",
      "MAE BoxCox, Transformed: 11.78\n"
     ]
    }
   ],
   "source": [
    "predictions = random_search.predict(val_X)\n",
    "\n",
    "# Check GOF, Calculate MAE\n",
    "errors = abs(val_Y - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "\n",
    "print('MAE BoxCox:', round(np.mean(errors), 2))\n",
    "print('MAE BoxCox, Transformed:', round(np.mean(errors_trans), 2))\n",
    "\n",
    "\n",
    "# Check out non-zero coefficients \n",
    "#coef = lasso_fit_bc.coef_\n",
    "\n",
    "#train_X.columns[coef != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best params to fit some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(learning_rate=0.1, n_estimators=1000, objective='reg:linear', eval_metric='mae',\n",
    "                    silent=True, **random_search.best_params_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.97\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X, train_Y)\n",
    "predictions = xgb.predict(val_X)\n",
    "errors = abs(val_Y - predictions)\n",
    "print(\"MAE: \", round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoxCox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Boxcox:  0.97\n",
      "MAE un-Boxcox:  11.78\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X_bc, train_Y_bc)\n",
    "predictions = xgb.predict(val_X_bc)\n",
    "errors = abs(val_Y_bc - predictions)\n",
    "errors_trans = abs(val_Y - inv_boxcox(predictions, lmda))\n",
    "print(\"MAE Boxcox: \", round(np.mean(errors), 2))\n",
    "print(\"MAE un-Boxcox: \", round(np.mean(errors_trans), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, We must standardize the input to be between 1 and 0\n",
    "\n",
    "Also, let's start off with only the features identified to be useful to lasso!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_std(column):\n",
    "    # Helper function, range standardizes a list of values\n",
    "    return (column - column.min())/(column.max() - column.min())\n",
    "\n",
    "def range_std_reversible(column):\n",
    "    # Helper function, range standardizes a list of values\n",
    "    # Returns min and max for later reversal\n",
    "    return (column - column.min())/(column.max() - column.min()), column.min(), column.max()\n",
    "\n",
    "def range_std_reverse(column, min_val, max_value):\n",
    "    return (column*(max_value - min_val) + min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_standardize = [*lasso_features, 'target']\n",
    "df_thin = df.loc[:, features_to_standardize]\n",
    "for column_name in features_to_standardize:\n",
    "    df_thin[column_name] = range_std(df_thin[column_name])\n",
    "    \n",
    "df_thin.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split features and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these as our training set\n",
    "trainY_std = df_thin.loc[:, 'target']\n",
    "trainX_std = df_thin.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxcox transform\n",
    "trainY_std_bc, min_value, max_value = range_std_reversible(Y_boxcox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_std, val_X_std, train_Y_std, val_Y_std = train_test_split(trainX_std, trainY_std, test_size = 0.20, random_state = 42)\n",
    "train_X_std_bc, val_X_std_bc, train_Y_std_bc, val_Y_std_bc = train_test_split(trainX_std, trainY_std_bc, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.639999, 19.919998, 21.150001, ..., 23.36    , 20.1407  ,\n",
       "       21.3     ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how we will return the range standardized, boxcox transformed values to their original scale\n",
    "inv_boxcox(range_std_reverse(trainY_std_bc, min_value, max_value), lmda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9336471051621303\n",
      "MAE, bc: 0.9324778352168116\n"
     ]
    }
   ],
   "source": [
    "std_error = abs(range_std_reverse(val_Y_std, df.target.min(), df.target.max()) - range_std_reverse(val_Y_std.mean(), df.target.min(), df.target.max()))\n",
    "print(\"MAE:\", np.mean(std_error))\n",
    "\n",
    "std_error_bc = abs(inv_boxcox(range_std_reverse(val_Y_std_bc, Y_boxcox.min(), Y_boxcox.max()), lmda) - inv_boxcox(range_std_reverse(val_Y_std_bc.mean(), Y_boxcox.min(), Y_boxcox.max()), lmda))\n",
    "print(\"MAE, bc:\", np.mean(std_error_bc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Nueral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplemodel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(100, input_shape= (4,), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 2s 332us/step - loss: 0.1367\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0642\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 62us/step - loss: 0.0603\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0555\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0517\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0495\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0474\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0457\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0444\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0431\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0418\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 63us/step - loss: 0.0414\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0410\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0406\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0405\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0402\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0400\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0399\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0398\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0397\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0396\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0396\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0396\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0396\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0395\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0396\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0395\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0396\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0396\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0395\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 74us/step - loss: 0.0395\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 73us/step - loss: 0.0395\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0396\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0396\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0396\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 72us/step - loss: 0.0395\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0396\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 71us/step - loss: 0.0395\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 71us/step - loss: 0.0395\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0395\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 67us/step - loss: 0.0395\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0396\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0395\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0395\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 72us/step - loss: 0.0395\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 63us/step - loss: 0.0395\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0395\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 61us/step - loss: 0.0395\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 62us/step - loss: 0.0396\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x9521d0b860>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn = KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)\n",
    "snn.fit(train_X_std, train_Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 1s 453us/step\n",
      "MAE:  0.93963\n"
     ]
    }
   ],
   "source": [
    "preds = snn.predict(val_X_std)\n",
    "preds = range_std_reverse(preds, df.target.min(), df.target.max())\n",
    "actual = range_std_reverse(val_Y_std, df.target.min(), df.target.max())\n",
    "\n",
    "errors = abs(actual - preds)\n",
    "\n",
    "print(\"MAE: \", round(np.mean(errors), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxcox transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5080/5080 [==============================] - 1s 293us/step - loss: 0.1544\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0534\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0502\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0477\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 55us/step - loss: 0.0457\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0443\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 51us/step - loss: 0.0429\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0420\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0414\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0409\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0406\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0399\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0401\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 51us/step - loss: 0.0399\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0395\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0396\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0393\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0393\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0394\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0393\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0393\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0392\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0392\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0391\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0391\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0392\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 53us/step - loss: 0.0392\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0391\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0392\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0391\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 55us/step - loss: 0.0391\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 68us/step - loss: 0.0392\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0391\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 61us/step - loss: 0.0391\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0391\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 55us/step - loss: 0.0392\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0391\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0391\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0391\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 59us/step - loss: 0.0391\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 54us/step - loss: 0.0391\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0391\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 77us/step - loss: 0.0391\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 59us/step - loss: 0.0391\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 66us/step - loss: 0.0391\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 64us/step - loss: 0.0391\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 59us/step - loss: 0.0391\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 65us/step - loss: 0.0392\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 69us/step - loss: 0.0391\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0391\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 70us/step - loss: 0.0391\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 55us/step - loss: 0.0391\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 62us/step - loss: 0.0391\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 61us/step - loss: 0.0391\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 55us/step - loss: 0.0391\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0391\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0391\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0391\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0391\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0391\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0391\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0392\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 56us/step - loss: 0.0391\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 59us/step - loss: 0.0391\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 61us/step - loss: 0.0391\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0391\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 59us/step - loss: 0.0391\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 60us/step - loss: 0.0391\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 57us/step - loss: 0.0391\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 58us/step - loss: 0.0392\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 61us/step - loss: 0.0391\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 55us/step - loss: 0.0391\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 52us/step - loss: 0.0391\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 51us/step - loss: 0.0391\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 50us/step - loss: 0.0391\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 51us/step - loss: 0.0391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x951eef00f0>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn_std = KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)\n",
    "snn.fit(train_X_std_bc, train_Y_std_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 0s 35us/step\n",
      "MAE :  0.04\n",
      "MAE Native Scale:  0.94339\n"
     ]
    }
   ],
   "source": [
    "preds_raw = snn.predict(val_X_std_bc)\n",
    "preds = inv_boxcox(range_std_reverse(preds_raw, Y_boxcox.min(), Y_boxcox.max()), lmda)\n",
    "actual = inv_boxcox(range_std_reverse(val_Y_std_bc, min_value, max_value), lmda)\n",
    "\n",
    "errors = abs(actual - preds)\n",
    "\n",
    "print(\"MAE : \", round(np.mean(abs(val_Y_std_bc - preds_raw)), 2))\n",
    "print(\"MAE Native Scale: \", round(np.mean(errors), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Normal Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = pd.read_csv(\"target.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num1', 'num30', 'num37', 'num59'], dtype='object')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num1</th>\n",
       "      <th>num30</th>\n",
       "      <th>num37</th>\n",
       "      <th>num59</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6350.000000</td>\n",
       "      <td>6350.000000</td>\n",
       "      <td>6350.000000</td>\n",
       "      <td>6350.000000</td>\n",
       "      <td>(6350+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.097565</td>\n",
       "      <td>0.891458</td>\n",
       "      <td>0.735050</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>(0.6168195605350324+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.114833</td>\n",
       "      <td>0.062245</td>\n",
       "      <td>0.104127</td>\n",
       "      <td>0.288743</td>\n",
       "      <td>(0.0551010880080418+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.862720</td>\n",
       "      <td>0.688233</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>(0.5963608384885867+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.064139</td>\n",
       "      <td>0.904846</td>\n",
       "      <td>0.749047</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>(0.61959382335273+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.143567</td>\n",
       "      <td>0.935322</td>\n",
       "      <td>0.799315</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>(0.6424944271345217+0j)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>(1+0j)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              num1        num30        num37        num59  \\\n",
       "count  6350.000000  6350.000000  6350.000000  6350.000000   \n",
       "mean      0.097565     0.891458     0.735050     0.500000   \n",
       "std       0.114833     0.062245     0.104127     0.288743   \n",
       "min       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.007875     0.862720     0.688233     0.250000   \n",
       "50%       0.064139     0.904846     0.749047     0.500000   \n",
       "75%       0.143567     0.935322     0.799315     0.750000   \n",
       "max       1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                        target  \n",
       "count                (6350+0j)  \n",
       "mean   (0.6168195605350324+0j)  \n",
       "std    (0.0551010880080418+0j)  \n",
       "min                         0j  \n",
       "25%    (0.5963608384885867+0j)  \n",
       "50%      (0.61959382335273+0j)  \n",
       "75%    (0.6424944271345217+0j)  \n",
       "max                     (1+0j)  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_standardize = [*lasso_features, 'target']\n",
    "\n",
    "df_thin = norm_data.loc[:, features_to_standardize]\n",
    "df_thin.target = lambertw(df_thin.target)\n",
    "\n",
    "for column_name in features_to_standardize:\n",
    "    df_thin[column_name] = range_std(df_thin[column_name])\n",
    "    \n",
    "df_thin.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these as our training set\n",
    "trainY_std = df_thin.loc[:, 'target']\n",
    "trainX_std = df_thin.loc[:,lasso_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_std, val_X_std, train_Y_std, val_Y_std = train_test_split(trainX_std, trainY_std, test_size = 0.20, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730     0.050629\n",
       "2131    0.006585\n",
       "3070    0.004074\n",
       "4283    0.019692\n",
       "217     0.107404\n",
       "3545    0.009654\n",
       "4080    0.016731\n",
       "3674    0.011104\n",
       "6176    0.100648\n",
       "4615    0.025217\n",
       "3459    0.008531\n",
       "4373    0.021169\n",
       "465     0.072265\n",
       "5703    0.058328\n",
       "2981    0.003272\n",
       "1183    0.030178\n",
       "4040    0.015989\n",
       "3680    0.011149\n",
       "1263    0.027436\n",
       "3622    0.010403\n",
       "3214    0.005530\n",
       "746     0.049625\n",
       "1611    0.017378\n",
       "4684    0.026684\n",
       "80      0.152974\n",
       "3784    0.012268\n",
       "2882    0.002307\n",
       "1616    0.017331\n",
       "6296    0.143494\n",
       "3612    0.010402\n",
       "          ...   \n",
       "509     0.067894\n",
       "5772    0.061850\n",
       "2153    0.006585\n",
       "4851    0.030706\n",
       "748     0.049625\n",
       "1617    0.017331\n",
       "5271    0.041216\n",
       "2404    0.003159\n",
       "5986    0.078550\n",
       "3313    0.006657\n",
       "2024    0.008494\n",
       "4546    0.024115\n",
       "5556    0.051596\n",
       "2181    0.005990\n",
       "471     0.072009\n",
       "5139    0.037516\n",
       "3961    0.014874\n",
       "2619    0.000645\n",
       "5462    0.048389\n",
       "5996    0.079410\n",
       "3096    0.004402\n",
       "896     0.041879\n",
       "4796    0.028880\n",
       "251     0.097987\n",
       "1209    0.029393\n",
       "3525    0.009280\n",
       "3942    0.014595\n",
       "2895    0.002518\n",
       "1128    0.032141\n",
       "4724    0.027417\n",
       "Name: target, Length: 1270, dtype: float64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(val_Y_std - val_Y_std.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.03778143032920284\n"
     ]
    }
   ],
   "source": [
    "std_error = abs(val_Y_std - val_Y_std.mean())\n",
    "\n",
    "print(\"MAE:\", np.mean(std_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplemodel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(100, input_shape= (4,), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(4)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christopher\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py:492: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 2s 409us/step - loss: 0.1753\n",
      "Epoch 2/100\n",
      "5080/5080 [==============================] - 0s 81us/step - loss: 0.0726\n",
      "Epoch 3/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0669\n",
      "Epoch 4/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0631\n",
      "Epoch 5/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0598\n",
      "Epoch 6/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0552\n",
      "Epoch 7/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.0516\n",
      "Epoch 8/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0486\n",
      "Epoch 9/100\n",
      "5080/5080 [==============================] - 0s 93us/step - loss: 0.0457\n",
      "Epoch 10/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.0440\n",
      "Epoch 11/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0421\n",
      "Epoch 12/100\n",
      "5080/5080 [==============================] - 0s 92us/step - loss: 0.0408\n",
      "Epoch 13/100\n",
      "5080/5080 [==============================] - 0s 83us/step - loss: 0.0394\n",
      "Epoch 14/100\n",
      "5080/5080 [==============================] - 0s 94us/step - loss: 0.0386\n",
      "Epoch 15/100\n",
      "5080/5080 [==============================] - 1s 100us/step - loss: 0.0382\n",
      "Epoch 16/100\n",
      "5080/5080 [==============================] - 0s 83us/step - loss: 0.0376\n",
      "Epoch 17/100\n",
      "5080/5080 [==============================] - 0s 83us/step - loss: 0.0372\n",
      "Epoch 18/100\n",
      "5080/5080 [==============================] - 0s 93us/step - loss: 0.0370\n",
      "Epoch 19/100\n",
      "5080/5080 [==============================] - 1s 111us/step - loss: 0.0368\n",
      "Epoch 20/100\n",
      "5080/5080 [==============================] - 0s 94us/step - loss: 0.0366\n",
      "Epoch 21/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0365\n",
      "Epoch 22/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0364\n",
      "Epoch 23/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0363\n",
      "Epoch 24/100\n",
      "5080/5080 [==============================] - 0s 81us/step - loss: 0.0362\n",
      "Epoch 25/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.0362\n",
      "Epoch 26/100\n",
      "5080/5080 [==============================] - 0s 84us/step - loss: 0.0362\n",
      "Epoch 27/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0362\n",
      "Epoch 28/100\n",
      "5080/5080 [==============================] - 0s 96us/step - loss: 0.0362\n",
      "Epoch 29/100\n",
      "5080/5080 [==============================] - 0s 95us/step - loss: 0.0361\n",
      "Epoch 30/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 31/100\n",
      "5080/5080 [==============================] - 0s 92us/step - loss: 0.0361\n",
      "Epoch 32/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 33/100\n",
      "5080/5080 [==============================] - 0s 89us/step - loss: 0.0361\n",
      "Epoch 34/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 35/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 36/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 37/100\n",
      "5080/5080 [==============================] - 0s 90us/step - loss: 0.0361\n",
      "Epoch 38/100\n",
      "5080/5080 [==============================] - 0s 95us/step - loss: 0.0361\n",
      "Epoch 39/100\n",
      "5080/5080 [==============================] - 0s 89us/step - loss: 0.0361\n",
      "Epoch 40/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0361\n",
      "Epoch 41/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0361\n",
      "Epoch 42/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 43/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 44/100\n",
      "5080/5080 [==============================] - 0s 90us/step - loss: 0.0361\n",
      "Epoch 45/100\n",
      "5080/5080 [==============================] - 0s 96us/step - loss: 0.0361\n",
      "Epoch 46/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0361\n",
      "Epoch 47/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 48/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 49/100\n",
      "5080/5080 [==============================] - 0s 91us/step - loss: 0.0361\n",
      "Epoch 50/100\n",
      "5080/5080 [==============================] - 0s 89us/step - loss: 0.0361\n",
      "Epoch 51/100\n",
      "5080/5080 [==============================] - 0s 93us/step - loss: 0.0361\n",
      "Epoch 52/100\n",
      "5080/5080 [==============================] - 0s 98us/step - loss: 0.0361\n",
      "Epoch 53/100\n",
      "5080/5080 [==============================] - 0s 91us/step - loss: 0.0361\n",
      "Epoch 54/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0361\n",
      "Epoch 55/100\n",
      "5080/5080 [==============================] - 0s 96us/step - loss: 0.0361\n",
      "Epoch 56/100\n",
      "5080/5080 [==============================] - 0s 96us/step - loss: 0.0361\n",
      "Epoch 57/100\n",
      "5080/5080 [==============================] - 0s 93us/step - loss: 0.0361\n",
      "Epoch 58/100\n",
      "5080/5080 [==============================] - 0s 96us/step - loss: 0.0362\n",
      "Epoch 59/100\n",
      "5080/5080 [==============================] - 0s 95us/step - loss: 0.0361\n",
      "Epoch 60/100\n",
      "5080/5080 [==============================] - 0s 94us/step - loss: 0.0361\n",
      "Epoch 61/100\n",
      "5080/5080 [==============================] - 0s 89us/step - loss: 0.0361\n",
      "Epoch 62/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 63/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0361\n",
      "Epoch 64/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 65/100\n",
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0361\n",
      "Epoch 66/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.0361\n",
      "Epoch 67/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 68/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 69/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 70/100\n",
      "5080/5080 [==============================] - 0s 90us/step - loss: 0.0361\n",
      "Epoch 71/100\n",
      "5080/5080 [==============================] - 0s 83us/step - loss: 0.0361\n",
      "Epoch 72/100\n",
      "5080/5080 [==============================] - 0s 93us/step - loss: 0.0361\n",
      "Epoch 73/100\n",
      "5080/5080 [==============================] - 0s 91us/step - loss: 0.0361\n",
      "Epoch 74/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 75/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 76/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 77/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0361\n",
      "Epoch 78/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 79/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 80/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0361\n",
      "Epoch 81/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0361\n",
      "Epoch 82/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 83/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0360\n",
      "Epoch 84/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 85/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0360\n",
      "Epoch 86/100\n",
      "5080/5080 [==============================] - 0s 87us/step - loss: 0.0361\n",
      "Epoch 87/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 88/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 89/100\n",
      "5080/5080 [==============================] - 0s 90us/step - loss: 0.0361\n",
      "Epoch 90/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0361\n",
      "Epoch 91/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0361\n",
      "Epoch 92/100\n",
      "5080/5080 [==============================] - 0s 84us/step - loss: 0.0361\n",
      "Epoch 93/100\n",
      "5080/5080 [==============================] - 0s 85us/step - loss: 0.0361\n",
      "Epoch 94/100\n",
      "5080/5080 [==============================] - 0s 88us/step - loss: 0.0361\n",
      "Epoch 95/100\n",
      "5080/5080 [==============================] - 0s 86us/step - loss: 0.0360\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5080/5080 [==============================] - 0s 82us/step - loss: 0.0361\n",
      "Epoch 97/100\n",
      "5080/5080 [==============================] - 0s 77us/step - loss: 0.0361\n",
      "Epoch 98/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.0361\n",
      "Epoch 99/100\n",
      "5080/5080 [==============================] - 0s 78us/step - loss: 0.0361\n",
      "Epoch 100/100\n",
      "5080/5080 [==============================] - 0s 80us/step - loss: 0.0361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x95239cbc50>"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn = KerasRegressor(build_fn=simplemodel, epochs=100, verbose=True)\n",
    "snn.fit(train_X_std, train_Y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270/1270 [==============================] - 0s 39us/step\n",
      "MAE:  0.03743\n",
      "MAE Lambart Scale:  0.03743\n",
      "MAE Native Scale Baseline: 0.1115639153233884\n",
      "Model MAE:  0.1108048787456431\n"
     ]
    }
   ],
   "source": [
    "preds = snn.predict(val_X_std)\n",
    "\n",
    "errors = abs(val_Y_std - preds)\n",
    "print(\"MAE: \", round(np.mean(errors), 5))\n",
    "\n",
    "# Rescale from the 0 - 1 scale\n",
    "errors = abs(range_std_reverse(val_Y_std, df_thin.target.min(), df_thin.target.max()) - range_std_reverse(preds, df_thin.target.min(), df_thin.target.max()))\n",
    "print(\"MAE Lambart Scale: \", round(np.mean(errors), 5))\n",
    "# 0.1241036151090745 baseline\n",
    "\n",
    "# Covnert to native scale\n",
    "actual_lam = range_std_reverse(val_Y_std, df_thin.target.min(), df_thin.target.max())\n",
    "pred_lam = range_std_reverse(val_Y_std.mean(),  df_thin.target.min(), df_thin.target.max())\n",
    "predictions_lam = range_std_reverse(preds,  df_thin.target.min(), df_thin.target.max())\n",
    "\n",
    "\n",
    "std_error = abs(actual_lam*np.exp(actual_lam) - pred_lam*np.exp(pred_lam) )\n",
    "std_error_model = abs(actual_lam*np.exp(actual_lam) - predictions_lam*np.exp(pred_lam) )\n",
    "\n",
    "\n",
    "print(\"MAE Native Scale Baseline:\", np.mean(std_error))\n",
    "\n",
    "print(\"Model MAE: \", np.mean(std_error_model) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730      (0.563716097900908+0j)\n",
       "2131     (0.607760836636326+0j)\n",
       "3070    (0.6184198843230663+0j)\n",
       "4283    (0.6340379506406371+0j)\n",
       "217      (0.506941831572853+0j)\n",
       "3545     (0.623999725574594+0j)\n",
       "4080     (0.631076236804234+0j)\n",
       "3674    (0.6254499216217124+0j)\n",
       "6176    (0.7149932866225828+0j)\n",
       "4615    (0.6395628852916331+0j)\n",
       "3459    (0.6228770190956557+0j)\n",
       "4373     (0.635514570175142+0j)\n",
       "465     (0.5420808814436198+0j)\n",
       "5703    (0.6726735540671426+0j)\n",
       "2981    (0.6176176731793163+0j)\n",
       "1183    (0.5841679809726658+0j)\n",
       "4040     (0.630334342774798+0j)\n",
       "3680    (0.6254947610558818+0j)\n",
       "1263    (0.5869092248849136+0j)\n",
       "3622    (0.6247481567721125+0j)\n",
       "3214    (0.6198757654709789+0j)\n",
       "746     (0.5647203542073441+0j)\n",
       "1611    (0.5969678823987247+0j)\n",
       "4684    (0.6410297934334482+0j)\n",
       "80      (0.4613716886460632+0j)\n",
       "3784    (0.6266139965278106+0j)\n",
       "2882    (0.6166521228858421+0j)\n",
       "1616    (0.5970141616144082+0j)\n",
       "6296    (0.7578394630322706+0j)\n",
       "3612    (0.6247475962602763+0j)\n",
       "                 ...           \n",
       "509     (0.5464516120544715+0j)\n",
       "5772    (0.6761954814143439+0j)\n",
       "2153     (0.607760836636326+0j)\n",
       "4851    (0.6450513204391733+0j)\n",
       "748     (0.5647209565421384+0j)\n",
       "1617    (0.5970141616144082+0j)\n",
       "5271    (0.6555620702296208+0j)\n",
       "2404    (0.6111863780644307+0j)\n",
       "5986    (0.6928954414137255+0j)\n",
       "3313     (0.621002508513021+0j)\n",
       "2024    (0.6058517864478374+0j)\n",
       "4546    (0.6384606004023514+0j)\n",
       "5556    (0.6659419479652241+0j)\n",
       "2181    (0.6083553417232922+0j)\n",
       "471     (0.5423368005432673+0j)\n",
       "5139    (0.6518619105844382+0j)\n",
       "3961    (0.6292198200150706+0j)\n",
       "2619    (0.6137001785028524+0j)\n",
       "5462    (0.6627343998573454+0j)\n",
       "5996     (0.693755996217975+0j)\n",
       "3096    (0.6187474633625198+0j)\n",
       "896     (0.5724664565126444+0j)\n",
       "4796    (0.6432259482998368+0j)\n",
       "251     (0.5163587528339976+0j)\n",
       "1209     (0.584952388126811+0j)\n",
       "3525    (0.6236258571887247+0j)\n",
       "3942    (0.6289410128106425+0j)\n",
       "2895     (0.616863391133085+0j)\n",
       "1128    (0.5822041402866981+0j)\n",
       "4724    (0.6417623025704257+0j)\n",
       "Name: target, Length: 1270, dtype: complex128"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import lambertw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730     3.117035e+09\n",
       "2131    7.507361e+09\n",
       "3070    1.002766e+10\n",
       "4283    1.542625e+10\n",
       "217     1.734977e+09\n",
       "3545    1.171921e+10\n",
       "4080    1.424669e+10\n",
       "3674    1.220266e+10\n",
       "6176    6.048353e+10\n",
       "4615    1.780192e+10\n",
       "3459    1.135736e+10\n",
       "4373    1.603958e+10\n",
       "465     2.379429e+09\n",
       "5703    3.523446e+10\n",
       "2981    9.806298e+09\n",
       "1183    4.384284e+09\n",
       "4040    1.396215e+10\n",
       "3680    1.221789e+10\n",
       "1263    4.627460e+09\n",
       "3622    1.196646e+10\n",
       "3214    1.044330e+10\n",
       "746     3.162620e+09\n",
       "1611    5.750513e+09\n",
       "4684    1.846803e+10\n",
       "80      1.309340e+09\n",
       "3784    1.260375e+10\n",
       "2882    9.547015e+09\n",
       "1616    5.756674e+09\n",
       "6296    8.645058e+10\n",
       "3612    1.196627e+10\n",
       "            ...     \n",
       "509     2.498210e+09\n",
       "5772    3.727436e+10\n",
       "2153    7.507361e+09\n",
       "4851    2.036251e+10\n",
       "748     3.162647e+09\n",
       "1617    5.756674e+09\n",
       "5271    2.570949e+10\n",
       "2404    8.221740e+09\n",
       "5986    4.715180e+10\n",
       "3313    1.077738e+10\n",
       "2024    7.144944e+09\n",
       "4546    1.731076e+10\n",
       "5556    3.139891e+10\n",
       "2181    7.625310e+09\n",
       "471     2.386058e+09\n",
       "5139    2.377025e+10\n",
       "3961    1.354313e+10\n",
       "2619    8.801804e+09\n",
       "5462    2.960729e+10\n",
       "5996    4.766720e+10\n",
       "3096    1.011961e+10\n",
       "896     3.562903e+09\n",
       "4796    1.949067e+10\n",
       "251     1.867553e+09\n",
       "1209    4.451550e+09\n",
       "3525    1.159750e+10\n",
       "3942    1.343990e+10\n",
       "2895    9.603084e+09\n",
       "1128    4.223521e+09\n",
       "4724    1.880581e+10\n",
       "Name: target_norm, Length: 1270, dtype: float64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_test = range_std_reverse(val_Y_std, norm_data.target_norm.min(), norm_data.target_norm.max())\n",
    "\n",
    "val_y_test*np.exp(val_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
